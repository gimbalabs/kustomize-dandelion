apiVersion: v1
kind: ConfigMap
metadata:
  name: cardano-db-sync-configmap
data:
  create-db-ro-user-entrypoint: |
    export PGCONNECT_TIMEOUT=10
    while [ -z "$(psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -c '\dt' ${POSTGRES_DB} | grep epoch)" ]
    do
      sleep 1
    done
    envsubst < /configmap/create-ro-user.sql.tpl > /tmp/create-ro-user.sql
    psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -f /tmp/create-ro-user.sql ${POSTGRES_DB}
    psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -f /configmap/extra.sql ${POSTGRES_DB}
  create-ro-user.sql.tpl: |
    CREATE ROLE ${POSTGRES_USER_RO};
    GRANT CONNECT ON DATABASE ${POSTGRES_DB} TO ${POSTGRES_USER_RO};
    GRANT SELECT ON ALL TABLES IN SCHEMA public TO ${POSTGRES_USER_RO};
    GRANT USAGE ON SCHEMA public TO ${POSTGRES_USER_RO};
    ALTER ROLE ${POSTGRES_USER_RO} WITH login;
    ALTER USER ${POSTGRES_USER_RO} WITH PASSWORD '${POSTGRES_PASSWORD_RO}';
    GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA PUBLIC TO ${POSTGRES_USER_RO};
  extra.sql: |
    CREATE OR REPLACE FUNCTION get_tx_history_for_addresses(data json) RETURNS TABLE (tx_hash text, block word31type, tx_timestamp timestamp) AS $$
    DECLARE
      addresses text[];
    BEGIN
      addresses := (SELECT array_agg(replace(rec::text, '"', ''))
                    FROM json_array_elements(data->'addresses') rec);
      RETURN QUERY (SELECT trim(txs.hash, '\\\\x') , txs.block_no, txs.time from (
        SELECT
          tx.id, tx.hash::text, block.block_no, block.hash::text as blockHash, block.time, tx.block_index
          FROM block
          INNER JOIN tx ON block.id = tx.block_id
          INNER JOIN tx_out ON tx.id = tx_out.tx_id
          WHERE tx_out.address = ANY(addresses)
        UNION
          SELECT DISTINCT
            tx.id, tx.hash::text, block.block_no, block.hash::text as blockHash, block.time, tx.block_index
            FROM block
            INNER JOIN tx ON block.id = tx.block_id
            INNER JOIN tx_in ON tx.id = tx_in.tx_in_id
            INNER JOIN tx_out ON (tx_in.tx_out_id = tx_out.tx_id) AND (tx_in.tx_out_index = tx_out.index)
            WHERE tx_out.address = ANY(addresses)
            ORDER BY time DESC
      ) AS txs);
    END; $$ LANGUAGE PLPGSQL IMMUTABLE;

    CREATE OR REPLACE FUNCTION get_eoe_balance_for_addresses(data json) RETURNS TABLE (balance numeric, address character varying) AS $$
    DECLARE
      addresses text[];
      epoch int;
    BEGIN
      addresses := (SELECT array_agg(replace(rec::text, '"', ''))
                    FROM json_array_elements(data->'addresses') rec);
      SELECT json_extract_path_text(data, 'epoch') INTO epoch AS tmp;
      RETURN QUERY (SELECT SUM(utxo_view.value), utxo_view.address FROM utxo_view
        INNER JOIN tx ON tx.id = utxo_view.tx_id
        INNER JOIN block ON block.id = tx.block_id
        WHERE utxo_view.address = ANY(addresses)
        AND block.slot_no <= (select get_last_slot_for_epoch(epoch))
        GROUP BY utxo_view.address);
    END; $$ LANGUAGE PLPGSQL IMMUTABLE;

    CREATE FUNCTION get_metadata(metadatum word64type default 0, epochs int[] default null) RETURNS TABLE (epoch word31type, data jsonb) AS $$
    BEGIN
      IF epochs IS NOT NULL THEN
        RETURN QUERY (select block.epoch_no, json as epoch from tx_metadata
                      inner join tx on tx_metadata.tx_id = tx.id
                      inner join block on tx.block_id = block.id
                      where key = metadatum and epoch_no = ANY(epochs)
                      order by epoch_no);
      ELSE
        RETURN QUERY (select block.epoch_no, json as epoch from tx_metadata
                      inner join tx on tx_metadata.tx_id = tx.id
                      inner join block on tx.block_id = block.id
                      where key = metadatum
                      order by epoch_no);
      END IF;
    END; $$ LANGUAGE PLPGSQL IMMUTABLE;

    CREATE OR REPLACE FUNCTION get_pools_dbsync_hash_id(_pool_bech32_ids text[] DEFAULT null) RETURNS TABLE (pool_dbsync_hash_id bigint, pool_bech32_id character varying, vrf_key_hash character varying) AS $$
    select distinct pool_hash.id, pool_hash.view, encode(pool_update.vrf_key_hash, 'hex') from pool_update 
                  inner join pool_hash on pool_update.hash_id = pool_hash.id
                  where pool_update.registered_tx_id in (select max(pool_update.registered_tx_id) from pool_update group by hash_id)
                  and not exists
                  ( select * from pool_retire where pool_retire.hash_id = pool_update.hash_id
                    and pool_retire.retiring_epoch <= (select max (epoch_no) from block)
                  ) 
                  AND CASE
                  WHEN _pool_bech32_ids IS NULL THEN true
                  WHEN _pool_bech32_ids IS NOT NULL THEN pool_hash.view = ANY(SELECT UNNEST(_pool_bech32_ids))
                  END;
    $$ LANGUAGE SQL IMMUTABLE;
  initContainer-entrypoint: |
    function finish-socat {
      pkill -f socat && sleep 1
      rm -f ${CARDANO_NODE_SOCKET_PATH}
    }

    trap finish-socat EXIT

    export PGCONNECT_TIMEOUT=10

    case "${NETWORK}" in
      "mainnet") S3_BUCKET_URI=${DB_SYNC_SNAPSHOT_MAINNET_S3_BUCKET_URI};;
      "testnet") S3_BUCKET_URI=${DB_SYNC_SNAPSHOT_TESTNET_S3_BUCKET_URI};;
    esac

    if [ "${RESTORE_SNAPSHOT}" == "true" ]
    then
      until psql -P pager=off -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -c '\dt' ${POSTGRES_DB}
      do
        sleep 1
      done
      if [ -z "$(psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -c '\dt' ${POSTGRES_DB} | grep epoch)" ]
      then
        cd /aux-data-dir

        read -d "\n" DB_SYNC_SNAPSHOT DB_SYNC_SNAPSHOT_SHA256_SUM <<<$(aws s3 ls --no-sign-request ${S3_BUCKET_URI} | awk '{print $NF}' | sort | tail -n2)

        aws s3 cp --no-sign-request ${S3_BUCKET_URI}${DB_SYNC_SNAPSHOT} snapshot.tgz
        aws s3 cp --no-sign-request ${S3_BUCKET_URI}${DB_SYNC_SNAPSHOT_SHA256_SUM} snapshot.tgz.sha256sum.tmp

        echo $(awk '{print $1}' snapshot.tgz.sha256sum.tmp) snapshot.tgz > snapshot.tgz.sha256sum
        sha256sum --check --status < snapshot.tgz.sha256sum
        if [ $? -eq 0 ]
        then
          tar -zxf snapshot.tgz
          psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -f *sql ${POSTGRES_DB}
          rm -f *sql
          mv *state* /db-sync-statedir
          chown -R root: /db-sync-statedir
        else
          echo "[!] sha256sum check error for ${S3_BUCKET_URI}${DB_SYNC_SNAPSHOT}"
          exit 1
        fi
      fi
    fi
    DB_BLOCK_NO=$(psql -U ${POSTGRES_USER} -h ${POSTGRES_HOST} -tA -P pager=off -c 'select block_no from block order by id desc limit 1;' ${POSTGRES_DB})
    test -z "${DB_BLOCK_NO}" && DB_BLOCK_NO=0

    echo -n "[+] Waiting for cardano-node to become available (socat approach makes db-sync to freeze if it's not)..."
    while ! `echo > /dev/tcp/${CARDANO_NODE_SOCKET_TCP_HOST}/${CARDANO_NODE_SOCKET_TCP_PORT}`
    do
      sleep 1
      echo -n .
    done

    rm -f ${CARDANO_NODE_SOCKET_PATH}
    socat UNIX-LISTEN:${CARDANO_NODE_SOCKET_PATH},fork TCP:${CARDANO_NODE_SOCKET_TCP_HOST}:${CARDANO_NODE_SOCKET_TCP_PORT},ignoreeof &
    while ! `timeout 10 cardano-cli query tip --mainnet 2>&1 | grep -q "epoch\|NodeToClientVersionData"`
    do
      sleep 1
      echo -n .
    done

    cardano-cli query tip --mainnet
    if [ $? -eq 0 ]
    then
      MAGIC_ARG="--mainnet"
    else
      MAGIC_ARG="--testnet-magic $(cardano-cli query tip --mainnet 2>&1 | sed 's|\(.*NodeToClientVersionData.*\)unNetworkMagic = \(.*\)}}.*/=\(.*\)|\2|g' | xargs echo)"
    fi

    echo -n "[+] Waiting for cardano-node to reach tip..."
    while [[ -n $(cardano-cli query tip ${MAGIC_ARG} | jq -r .block) ]] && [ ${DB_BLOCK_NO} -gt $(cardano-cli query tip ${MAGIC_ARG} | jq -r .block) ]
    do
      sleep 60
      echo -n .
    done

  liveness-healthcheck: |
    KUBE_API_URL=https://kubernetes.default.svc/api/v1/namespaces
    KUBE_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
    NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
    SINCE_SECONDS=300
    curl -m 30 -sSk -H "Authorization: Bearer $KUBE_TOKEN" "${KUBE_API_URL}/${NAMESPACE}/pods/cardano-db-sync-0/log?container=cardano-db-sync&sinceSeconds=${SINCE_SECONDS}" > /tmp/db-sync-log-tail 
    if [ $? -ne 0 ]
    then
      exit 0
    else
      grep -q "libpq.*failed.*no connection to the server" /tmp/db-sync-log-tail
      if [ $? -eq 0 ]
      then
        echo "[!] Postgres connection lost, failing healthcheck..."
        exit 1
      fi
    fi
